found 3 groups in the given directoryGroup 0 with name = SEQ (52 files)
number of Paradigma: 3
... with number of blocks: 10 10 10  
Group 1 with name = SRTT (43 files)
number of Paradigma: 2
... with number of blocks: 6 2  
Group 2 with name = MST (49 files)
number of Paradigma: 1
... with number of blocks: 12  
checking dataconsistency ...
checking that every experiment file of a given type and day has the same number of paradigma
____________________________________
analysing Group SEQ
subj   0 file=10_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj   1 file=10_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj   2 file=15_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj   3 file=15_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj   4 file=16_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj   5 file=16_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj   6 file=17_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj   7 file=17_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj   8 file=18_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj   9 file=18_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  10 file=19_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  11 file=19_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  12 file=20_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  13 file=20_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  14 file=21_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  15 file=21_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  16 file=22_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  17 file=23_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  18 file=23_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  19 file=24_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  20 file=24_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  21 file=25_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  22 file=25_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  23 file=26_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  24 file=26_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  25 file=27_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  26 file=27_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  27 file=28_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  28 file=28_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  29 file=29_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  30 file=29_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  31 file=30_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  32 file=30_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  33 file=31_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  34 file=31_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  35 file=32_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  36 file=33_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  37 file=33_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  38 file=34_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  39 file=34_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  40 file=35_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  41 file=35_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  42 file=36_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  43 file=36_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  44 file=37_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  45 file=37_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  46 file=38_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  47 file=38_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  48 file=39_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  49 file=39_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  50 file=40_SEQ_1_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
subj  51 file=40_SEQ_2_8 num_p = 3 num_bloecke = [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] .... to
____________________________________
analysing Group SRTT
subj   0 file=10_SRTT_1_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj   1 file=10_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj   2 file=16_SRTT_1_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj   3 file=16_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj   4 file=17_SRTT_1_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj   5 file=17_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj   6 file=18_SRTT_1_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj   7 file=18_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj   8 file=19_SRTT_1_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj   9 file=19_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  10 file=20_SRTT_1_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  11 file=20_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  12 file=21_SRTT_1_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  13 file=21_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  14 file=23_SRTT_1_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  15 file=23_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  16 file=24_SRTT_1_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  17 file=24_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  18 file=25_SRTT_1_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  19 file=25_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  20 file=28_SRTT_1_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  21 file=28_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  22 file=29_SRTT_1_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  23 file=29_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  24 file=31_SRTT_1_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  25 file=31_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  26 file=32_SRTT_1_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  27 file=32_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  28 file=33_SRTT_1_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  29 file=33_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  30 file=34_SRTT_1_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  31 file=34_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  32 file=35_SRTT_1_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  33 file=35_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  34 file=36_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  35 file=37_SRTT_1_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  36 file=37_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  37 file=38_SRTT_1_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  38 file=38_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  39 file=39_SRTT_1_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  40 file=39_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  41 file=40_SRTT_1_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
subj  42 file=40_SRTT_2_10 num_p = 2 num_bloecke = [[7, 7, 7, 7, 7, 7], [7, 7]] .... to
____________________________________
analysing Group MST
subj   0 file=15_MST_1_5 num_p = 1 num_bloecke = [[6, 5, 6, 8, 9, 10, 10, 12, 12, 13, 13, 11]] .... to
subj   1 file=15_MST_2_5 num_p = 1 num_bloecke = [[9, 12, 12, 13, 14, 12, 14, 12, 14, 13, 14, 14]] .... to
subj   2 file=16_MST_1_5 num_p = 1 num_bloecke = [[4, 7, 10, 12, 13, 12, 15, 16, 17, 15, 14, 14]] .... to
subj   3 file=16_MST_2_5 num_p = 1 num_bloecke = [[14, 17, 17, 17, 17, 18, 18, 16, 17, 18, 18, 17]] .... to
subj   4 file=17_MST_1_5 num_p = 1 num_bloecke = [[6, 10, 11, 12, 12, 11, 12, 14, 17, 18, 16, 18]] .... to
subj   5 file=17_MST_2_5 num_p = 1 num_bloecke = [[12, 14, 17, 18, 21, 21, 21, 20, 19, 21, 23, 23]] .... to
subj   6 file=18_MST_1_5 num_p = 1 num_bloecke = [[2, 3, 4, 5, 7, 8, 7, 7, 6, 5, 3, 8]] .... to
subj   7 file=18_MST_2_5 num_p = 1 num_bloecke = [[6, 8, 10, 12, 10, 13, 14, 13, 9, 13, 14, 15]] .... to
subj   8 file=19_MST_2_5 num_p = 1 num_bloecke = [[12, 14, 15, 15, 16, 16, 16, 15, 17, 17, 17, 18]] .... to
subj   9 file=20_MST_1_5 num_p = 1 num_bloecke = [[5, 11, 17, 19, 20, 19, 21, 20, 21, 23, 14, 23]] .... to
subj  10 file=20_MST_2_5 num_p = 1 num_bloecke = [[18, 26, 24, 25, 27, 27, 27, 26, 27, 25, 26, 27]] .... to
subj  11 file=21_MST_1_5 num_p = 1 num_bloecke = [[5, 6, 6, 8, 8, 9, 8, 7, 8, 8, 8, 9]] .... to
subj  12 file=21_MST_2_5 num_p = 1 num_bloecke = [[7, 7, 9, 10, 12, 12, 10, 9, 12, 12, 11, 11]] .... to
subj  13 file=22_MST_1_5 num_p = 1 num_bloecke = [[6, 7, 9, 8, 10, 11, 12, 13, 14, 10, 9, 13]] .... to
subj  14 file=22_MST_2_5 num_p = 1 num_bloecke = [[11, 13, 11, 12, 12, 13, 14, 15, 13, 12, 16, 15]] .... to
subj  15 file=23_MST_1_5 num_p = 1 num_bloecke = [[6, 7, 8, 8, 9, 9, 11, 11, 11, 12, 11, 12]] .... to
subj  16 file=23_MST_2_5 num_p = 1 num_bloecke = [[10, 14, 15, 13, 14, 15, 14, 14, 15, 15, 15, 16]] .... to
subj  17 file=24_MST_1_5 num_p = 1 num_bloecke = [[3, 5, 9, 9, 7, 8, 9, 10, 10, 12, 13, 14]] .... to
subj  18 file=24_MST_2_5 num_p = 1 num_bloecke = [[17, 19, 18, 18, 18, 20, 18, 21, 19, 20, 20, 20]] .... to
subj  19 file=25_MST_1_5 num_p = 1 num_bloecke = [[7, 12, 12, 17, 18, 18, 19, 17, 18, 20, 21, 22]] .... to
subj  20 file=25_MST_2_5 num_p = 1 num_bloecke = [[21, 23, 21, 23, 23, 20, 19, 20, 22, 19, 21, 24]] .... to
subj  21 file=26_MST_1_5 num_p = 1 num_bloecke = [[8, 11, 13, 14, 14, 14, 13, 14, 14, 11, 12, 13]] .... to
subj  22 file=26_MST_2_5 num_p = 1 num_bloecke = [[15, 16, 17, 18, 17, 16, 17, 19, 18, 18, 17, 16]] .... to
subj  23 file=27_MST_1_5 num_p = 1 num_bloecke = [[7, 8, 11, 10, 15, 13, 10, 16, 14, 14, 17, 13]] .... to
subj  24 file=27_MST_2_5 num_p = 1 num_bloecke = [[12, 21, 20, 21, 14, 18, 16, 15, 18, 17, 18, 18]] .... to
subj  25 file=28_MST_2_5 num_p = 1 num_bloecke = [[15, 16, 18, 20, 18, 19, 18, 20, 18, 18, 19, 17]] .... to
subj  26 file=29_MST_1_5 num_p = 1 num_bloecke = [[6, 10, 11, 13, 12, 13, 11, 12, 13, 14, 14, 14]] .... to
subj  27 file=29_MST_2_5 num_p = 1 num_bloecke = [[11, 14, 14, 16, 14, 14, 14, 14, 14, 14, 16, 14]] .... to
subj  28 file=30_MST_1_5 num_p = 1 num_bloecke = [[8, 10, 12, 9, 9, 8, 9, 11, 10, 11, 11, 9]] .... to
subj  29 file=30_MST_2_5 num_p = 1 num_bloecke = [[11, 14, 11, 14, 14, 14, 12, 15, 15, 15, 15, 16]] .... to
subj  30 file=31_MST_1_5 num_p = 1 num_bloecke = [[5, 8, 7, 8, 12, 14, 10, 14, 12, 14, 10, 13]] .... to
subj  31 file=31_MST_2_5 num_p = 1 num_bloecke = [[11, 14, 14, 15, 15, 15, 15, 11, 13, 15, 16, 13]] .... to
subj  32 file=32_MST_1_5 num_p = 1 num_bloecke = [[9, 13, 16, 13, 15, 15, 13, 11, 13, 15, 13, 16]] .... to
subj  33 file=32_MST_2_5 num_p = 1 num_bloecke = [[4, 9, 14, 17, 17, 20, 19, 19, 20, 18, 13, 18]] .... to
subj  34 file=33_MST_1_5 num_p = 1 num_bloecke = [[7, 8, 11, 11, 14, 13, 14, 13, 12, 15, 19, 20]] .... to
subj  35 file=33_MST_2_5 num_p = 1 num_bloecke = [[9, 18, 12, 16, 18, 21, 19, 20, 20, 19, 16, 19]] .... to
subj  36 file=34_MST_1_5 num_p = 1 num_bloecke = [[6, 11, 11, 16, 17, 22, 25, 24, 26, 27, 29, 27]] .... to
subj  37 file=34_MST_2_5 num_p = 1 num_bloecke = [[26, 28, 24, 25, 21, 25, 28, 24, 30, 25, 28, 28]] .... to
subj  38 file=35_MST_1_5 num_p = 1 num_bloecke = [[8, 11, 13, 11, 13, 12, 8, 13, 8, 13, 17, 16]] .... to
subj  39 file=35_MST_2_5 num_p = 1 num_bloecke = [[9, 20, 22, 19, 19, 21, 20, 17, 21, 22, 19, 20]] .... to
subj  40 file=36_MST_1_5 num_p = 1 num_bloecke = [[6, 11, 10, 13, 17, 16, 20, 14, 17, 16, 14, 19]] .... to
subj  41 file=36_MST_2_5 num_p = 1 num_bloecke = [[7, 18, 21, 22, 22, 26, 25, 24, 23, 25, 23, 23]] .... to
subj  42 file=37_MST_2_5 num_p = 1 num_bloecke = [[5, 12, 17, 15, 16, 11, 15, 16, 17, 17, 15, 16]] .... to
subj  43 file=38_MST_1_5 num_p = 1 num_bloecke = [[6, 9, 9, 10, 9, 12, 12, 12, 14, 11, 12, 11]] .... to
subj  44 file=38_MST_2_5 num_p = 1 num_bloecke = [[11, 13, 9, 13, 13, 17, 14, 15, 16, 17, 16, 15]] .... to
subj  45 file=39_MST_1_5 num_p = 1 num_bloecke = [[2, 8, 10, 12, 13, 14, 13, 13, 13, 11, 13, 14]] .... to
subj  46 file=39_MST_2_5 num_p = 1 num_bloecke = [[9, 13, 13, 15, 14, 14, 14, 11, 16, 14, 14, 14]] .... to
subj  47 file=40_MST_1_5 num_p = 1 num_bloecke = [[6, 8, 9, 11, 12, 11, 12, 13, 11, 12, 13, 14]] .... to
subj  48 file=40_MST_2_5 num_p = 1 num_bloecke = [[10, 13, 12, 15, 17, 17, 18, 18, 13, 18, 19, 21]] .... to
checking dataconsistency finished
______________________________________________
Question 1: Was there learning?
1.1. is there a linear increase in the number of correct sequences per block per paradigma (linear Regression)?
___________________________________________________
START____SEQ______________________________________
SEQ
1.1. is there a linear decrease in the Time to perform an sequence per block per paradigma (linear Regression)?
.... for day 1...
Regression across the mean of all subjects for each blocks ...
[[2.16293e+05 1.00000e+00]
 [2.08314e+05 1.00000e+00]
 [2.09225e+05 1.00000e+00]
 [2.08861e+05 1.00000e+00]
 [2.08899e+05 1.00000e+00]
 [2.07272e+05 1.00000e+00]
 [2.03370e+05 1.00000e+00]
 [2.02487e+05 1.00000e+00]
 [1.98873e+05 1.00000e+00]
 [1.93478e+05 1.00000e+00]]
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.865
Model:                            OLS   Adj. R-squared:                  0.848
Method:                 Least Squares   F-statistic:                     51.33
Date:                Fri, 11 Sep 2020   Prob (F-statistic):           9.57e-05
Time:                        13:17:24   Log-Likelihood:                -14.722
No. Observations:                  10   AIC:                             33.44
Df Residuals:                       8   BIC:                             34.05
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
x1            -0.0004   6.16e-05     -7.164      0.000      -0.001      -0.000
const         95.3531     12.687      7.516      0.000      66.097     124.609
==============================================================================
Omnibus:                        3.073   Durbin-Watson:                   1.197
Prob(Omnibus):                  0.215   Jarque-Bera (JB):                1.369
Skew:                          -0.905   Prob(JB):                        0.504
Kurtosis:                       2.912   Cond. No.                     7.00e+06
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large,  7e+06. This might indicate that there are
strong multicollinearity or other numerical problems.
.... for day 2...
Regression across the mean of all subjects for each blocks ...
[[1.61293e+05 1.00000e+00]
 [1.54743e+05 1.00000e+00]
 [1.57064e+05 1.00000e+00]
 [1.57263e+05 1.00000e+00]
 [1.54485e+05 1.00000e+00]
 [1.55854e+05 1.00000e+00]
 [1.54901e+05 1.00000e+00]
 [1.53584e+05 1.00000e+00]
 [1.52082e+05 1.00000e+00]
 [1.51670e+05 1.00000e+00]]
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.705
Model:                            OLS   Adj. R-squared:                  0.668
Method:                 Least Squares   F-statistic:                     19.13
Date:                Fri, 11 Sep 2020   Prob (F-statistic):            0.00237
Time:                        13:17:24   Log-Likelihood:                -18.635
No. Observations:                  10   AIC:                             41.27
Df Residuals:                       8   BIC:                             41.87
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
x1            -0.0009      0.000     -4.374      0.002      -0.001      -0.000
const        145.2668     32.189      4.513      0.002      71.038     219.496
==============================================================================
Omnibus:                       11.193   Durbin-Watson:                   1.780
Prob(Omnibus):                  0.004   Jarque-Bera (JB):                5.133
Skew:                          -1.590   Prob(JB):                       0.0768
Kurtosis:                       4.485   Cond. No.                     9.07e+06
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 9.07e+06. This might indicate that there are
strong multicollinearity or other numerical problems.
now use the slope of each subject and perform a t-test for the group
[-29.10989796 -42.44798535 -10.12595165  -5.4342836  -23.80241935
  -2.91203875 -17.1046613   -5.73003312 -18.55098151   2.79646547
 -13.27108516 -26.7218122   -9.93667214  -2.63827919 -24.66998285
 -21.88679029   5.59596727 -20.66904781  -9.03091452  -2.89674208
  -3.3762139  -18.52044127  29.8127471  -26.84187121 -10.37268773
  -4.36887218 -21.29358703]
cor_seqtimesum_slope_lpn t-test different from 0  p=9.992017633394741e-05 t=-4.587286872428713, m=-12.352150827432858, std=13.730089234766991
[  3.76481643 -33.51556449 -17.26232011  -1.55203025   8.30675923
  -0.85761783  -8.52759602  -0.48339029   3.60951877   0.5744616
  -5.67274423   4.62291744   7.53035562 -10.49138022 -15.60101936
   3.15357041   4.50599401 -12.65607985   2.06966507  -3.33354751
  -4.86841598  -3.45356658  -4.50221328  -9.38191396 -23.44297719]
cor_seqtimesum_slope_lpn t-test different from 0  p=0.02752085885707719 t=-2.34682807393318, m=-4.698572742648347, std=9.808222312211392
END____SEQ______________________________________
___________________________________________________
 
___________________________________________________
START____SRTT______________________________________
SRTT
1.1. is there a linear decrease in the Time to perform an sequence per block per paradigma (linear Regression)?
.... for day 1...
Regression across the mean of all subjects for each blocks ...
[[2.348200e+05 1.000000e+00]
 [2.243440e+05 1.000000e+00]
 [2.246670e+05 1.000000e+00]
 [2.177080e+05 1.000000e+00]
 [2.094710e+05 1.000000e+00]
 [2.198666e+05 1.000000e+00]]
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.639
Model:                            OLS   Adj. R-squared:                  0.549
Method:                 Least Squares   F-statistic:                     7.090
Date:                Fri, 11 Sep 2020   Prob (F-statistic):             0.0562
Time:                        13:17:24   Log-Likelihood:                -8.6657
No. Observations:                   6   AIC:                             21.33
Df Residuals:                       4   BIC:                             20.91
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
x1            -0.0002   6.65e-05     -2.663      0.056      -0.000    7.56e-06
const         41.7839     14.762      2.830      0.047       0.798      82.770
==============================================================================
Omnibus:                          nan   Durbin-Watson:                   1.614
Prob(Omnibus):                    nan   Jarque-Bera (JB):                1.782
Skew:                           1.314   Prob(JB):                        0.410
Kurtosis:                       3.468   Cond. No.                     6.39e+06
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 6.39e+06. This might indicate that there are
strong multicollinearity or other numerical problems.
.... for day 2...
Regression across the mean of all subjects for each blocks ...
[[2.12737e+05 1.00000e+00]
 [2.05346e+05 1.00000e+00]
 [1.97123e+05 1.00000e+00]
 [1.96755e+05 1.00000e+00]
 [1.97913e+05 1.00000e+00]
 [2.01852e+05 1.00000e+00]]
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.437
Model:                            OLS   Adj. R-squared:                  0.296
Method:                 Least Squares   F-statistic:                     3.099
Date:                Fri, 11 Sep 2020   Prob (F-statistic):              0.153
Time:                        13:17:24   Log-Likelihood:                -10.004
No. Observations:                   6   AIC:                             24.01
Df Residuals:                       4   BIC:                             23.59
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
x1            -0.0002      0.000     -1.760      0.153      -0.001       0.000
const         42.5260     22.746      1.870      0.135     -20.626     105.678
==============================================================================
Omnibus:                          nan   Durbin-Watson:                   0.624
Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.890
Skew:                           0.928   Prob(JB):                        0.641
Kurtosis:                       2.661   Cond. No.                     7.17e+06
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 7.17e+06. This might indicate that there are
strong multicollinearity or other numerical problems.
1.1. is there a linear decrease in the Time to perform an sequence per block per paradigma (linear Regression) ALLL?
.... for day 1...
Regression across the mean of all subjects for each blocks ...
[[2.35210e+05 1.00000e+00]
 [2.25315e+05 1.00000e+00]
 [2.25623e+05 1.00000e+00]
 [2.19168e+05 1.00000e+00]
 [2.15077e+05 1.00000e+00]
 [2.22717e+05 1.00000e+00]]
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.605
Model:                            OLS   Adj. R-squared:                  0.506
Method:                 Least Squares   F-statistic:                     6.119
Date:                Fri, 11 Sep 2020   Prob (F-statistic):             0.0687
Time:                        13:17:24   Log-Likelihood:                -8.9405
No. Observations:                   6   AIC:                             21.88
Df Residuals:                       4   BIC:                             21.46
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
x1            -0.0002   8.59e-05     -2.474      0.069      -0.000     2.6e-05
const         50.0529     19.230      2.603      0.060      -3.339     103.445
==============================================================================
Omnibus:                          nan   Durbin-Watson:                   1.357
Prob(Omnibus):                    nan   Jarque-Bera (JB):                1.765
Skew:                           1.302   Prob(JB):                        0.414
Kurtosis:                       3.526   Cond. No.                     8.02e+06
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 8.02e+06. This might indicate that there are
strong multicollinearity or other numerical problems.
.... for day 2...
Regression across the mean of all subjects for each blocks ...
[[2.13716e+05 1.00000e+00]
 [2.03231e+05 1.00000e+00]
 [1.98630e+05 1.00000e+00]
 [1.98013e+05 1.00000e+00]
 [1.95453e+05 1.00000e+00]
 [2.04448e+05 1.00000e+00]]
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.329
Model:                            OLS   Adj. R-squared:                  0.161
Method:                 Least Squares   F-statistic:                     1.962
Date:                Fri, 11 Sep 2020   Prob (F-statistic):              0.234
Time:                        13:17:24   Log-Likelihood:                -10.528
No. Observations:                   6   AIC:                             25.06
Df Residuals:                       4   BIC:                             24.64
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
x1            -0.0002      0.000     -1.401      0.234      -0.000       0.000
const         35.6353     23.669      1.506      0.207     -30.081     101.351
==============================================================================
Omnibus:                          nan   Durbin-Watson:                   0.668
Prob(Omnibus):                    nan   Jarque-Bera (JB):                1.414
Skew:                           1.188   Prob(JB):                        0.493
Kurtosis:                       3.123   Cond. No.                     6.85e+06
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 6.85e+06. This might indicate that there are
strong multicollinearity or other numerical problems.
now use the slope of each subject and perform a t-test for the group
[ -17.32955665  -61.07598039  -64.36491935 -249.34545455  -41.54126808
  -82.24118404  -91.01814672    3.37662338  -54.40882353  -36.61709402
  -69.49090909   54.9978022    -0.56017798  -39.11403509   21.37450593
  -62.65         -5.13870321 -127.88351648  -41.23199023  -97.7729064
 -116.81298701]
cor_seqtimesum_slope_lpn t-test different from 0  p=0.0006120113096157965 t=-4.059591596745455, m=-56.1356533960019, std=61.840278246441414
[ -34.90782609 -105.90246305   14.20084034  119.81318681  -99.27983871
  -63.28391248   -7.46184669 -117.94014681  135.60909091    1.65566502
 -125.02063983    3.25274725   -6.39274194  -14.37747036   42.60909091
  -27.34129555   -2.04605117  -26.82594417 -102.15584416   -1.88034188
  -55.7078686   -32.51759531]
cor_seqtimesum_slope_lpn t-test different from 0  p=0.12438959374598536 t=-1.600659332216261, m=-22.995509343042826, std=65.83453461184115
END____SRTT______________________________________
_________________________________________________
 
___________________________________________________
START____MST______________________________________
MST
1.1. is there a linear increase in the number of correct sequences per block per paradigma (linear Regression)?
.... for day 1...
Regression across the mean of all subjects for each blocks ...
[[124.   1.]
 [182.   1.]
 [214.   1.]
 [236.   1.]
 [276.   1.]
 [269.   1.]
 [277.   1.]
 [291.   1.]
 [296.   1.]
 [301.   1.]
 [297.   1.]
 [322.   1.]]
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.825
Model:                            OLS   Adj. R-squared:                  0.807
Method:                 Least Squares   F-statistic:                     47.07
Date:                Fri, 11 Sep 2020   Prob (F-statistic):           4.40e-05
Time:                        13:17:24   Log-Likelihood:                -21.445
No. Observations:                  12   AIC:                             46.89
Df Residuals:                      10   BIC:                             47.86
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.0565      0.008      6.861      0.000       0.038       0.075
const         -9.0252      2.166     -4.167      0.002     -13.851      -4.199
==============================================================================
Omnibus:                        0.531   Durbin-Watson:                   0.498
Prob(Omnibus):                  0.767   Jarque-Bera (JB):                0.538
Skew:                           0.122   Prob(JB):                        0.764
Kurtosis:                       1.992   Cond. No.                     1.25e+03
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.25e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
.... for day 2...
Regression across the mean of all subjects for each blocks ...
[[278.   1.]
 [395.   1.]
 [379.   1.]
 [417.   1.]
 [410.   1.]
 [436.   1.]
 [422.   1.]
 [405.   1.]
 [427.   1.]
 [427.   1.]
 [425.   1.]
 [441.   1.]]
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.488
Model:                            OLS   Adj. R-squared:                  0.437
Method:                 Least Squares   F-statistic:                     9.525
Date:                Fri, 11 Sep 2020   Prob (F-statistic):             0.0115
Time:                        13:17:24   Log-Likelihood:                -27.880
No. Observations:                  12   AIC:                             59.76
Df Residuals:                      10   BIC:                             60.73
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.0577      0.019      3.086      0.012       0.016       0.099
const        -17.8590      7.609     -2.347      0.041     -34.813      -0.905
==============================================================================
Omnibus:                        2.970   Durbin-Watson:                   0.681
Prob(Omnibus):                  0.226   Jarque-Bera (JB):                1.045
Skew:                          -0.091   Prob(JB):                        0.593
Kurtosis:                       1.566   Cond. No.                     3.97e+03
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 3.97e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
1.1. is there a linear decrease in the Time to perform an sequence per block per paradigma (linear Regression)?
.... for day 1...
Regression across the mean of all subjects for each blocks ...
[[1.19443e+05 1.00000e+00]
 [7.69710e+04 1.00000e+00]
 [6.86790e+04 1.00000e+00]
 [6.14370e+04 1.00000e+00]
 [5.69600e+04 1.00000e+00]
 [5.40590e+04 1.00000e+00]
 [5.31940e+04 1.00000e+00]
 [5.16030e+04 1.00000e+00]
 [5.10420e+04 1.00000e+00]
 [5.10390e+04 1.00000e+00]
 [5.03360e+04 1.00000e+00]
 [4.74560e+04 1.00000e+00]]
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.591
Model:                            OLS   Adj. R-squared:                  0.550
Method:                 Least Squares   F-statistic:                     14.46
Date:                Fri, 11 Sep 2020   Prob (F-statistic):            0.00347
Time:                        13:17:24   Log-Likelihood:                -26.528
No. Observations:                  12   AIC:                             57.06
Df Residuals:                      10   BIC:                             58.03
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
x1            -0.0001   3.63e-05     -3.802      0.003      -0.000   -5.72e-05
const         14.0437      2.353      5.969      0.000       8.801      19.286
==============================================================================
Omnibus:                        3.928   Durbin-Watson:                   0.490
Prob(Omnibus):                  0.140   Jarque-Bera (JB):                1.242
Skew:                           0.231   Prob(JB):                        0.538
Kurtosis:                       1.493   Cond. No.                     2.18e+05
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.18e+05. This might indicate that there are
strong multicollinearity or other numerical problems.
.... for day 2...
Regression across the mean of all subjects for each blocks ...
[[6.8540e+04 1.0000e+00]
 [5.1338e+04 1.0000e+00]
 [5.0053e+04 1.0000e+00]
 [4.6404e+04 1.0000e+00]
 [4.5689e+04 1.0000e+00]
 [4.4909e+04 1.0000e+00]
 [4.4625e+04 1.0000e+00]
 [4.5382e+04 1.0000e+00]
 [4.3698e+04 1.0000e+00]
 [4.3509e+04 1.0000e+00]
 [4.2368e+04 1.0000e+00]
 [4.2614e+04 1.0000e+00]]
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.559
Model:                            OLS   Adj. R-squared:                  0.515
Method:                 Least Squares   F-statistic:                     12.69
Date:                Fri, 11 Sep 2020   Prob (F-statistic):            0.00516
Time:                        13:17:24   Log-Likelihood:                -26.978
No. Observations:                  12   AIC:                             57.96
Df Residuals:                      10   BIC:                             58.92
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
x1            -0.0004      0.000     -3.563      0.005      -0.001      -0.000
const         23.2917      5.046      4.616      0.001      12.049      34.534
==============================================================================
Omnibus:                        3.383   Durbin-Watson:                   0.574
Prob(Omnibus):                  0.184   Jarque-Bera (JB):                1.099
Skew:                           0.079   Prob(JB):                        0.577
Kurtosis:                       1.526   Cond. No.                     3.34e+05
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 3.34e+05. This might indicate that there are
strong multicollinearity or other numerical problems.
now use the slope of each subject and perform a t-test for the group
[-20.26544407 -10.26389133 -11.3394412  -41.2703691   -5.29736845
 -16.60707619 -14.89901669 -17.75771304 -31.60964128  -6.04223648
  -1.9949943   -8.48011787  -8.46242428  -1.91866646 -15.94207122
  -3.27687869 -12.95937987  -7.0085184   -8.31861967  -8.52065818
 -10.15281964 -12.65994022 -12.74954061]
cor_seqtimesum_slope_lpn t-test different from 0  p=1.2572527705311362e-06 t=-6.589846336955434, m=-12.51290553226995, std=8.906236398959248
[ -4.49670597  -1.17345746  -3.43018397 -10.00582488  -2.80419661
  -0.77881951  -8.31665763  -3.14155607  -2.13803469  -1.2132764
  -0.43022181  -0.82095195   0.34770332  -1.8601457   -1.75185892
  -2.76103818  -1.58666226  -4.65041488  -3.45762676  -0.42564236
  -2.13985514  -1.56697124  -5.97673939  -4.47908533  -2.99051964
  -5.0078738 ]
cor_seqtimesum_slope_lpn t-test different from 0  p=1.6041871256447856e-06 t=-6.2340483721930475, m=-2.9637160471501285, std=2.3770396620354877
END____MST______________________________________
___________________________________________________
 
 
__________________________________________________________
________________________Q_________________________________
__________________________________________________________
We quantified chunking within each sequence by the optimized modularity Qmulti–trial of the
sequence networks. Modularity in this case measures the separability between clusters of
IKIs. Higher values of Q indicate a greater ease in separating chunks.
___________MST_______
Subject z-score for real Q 
[-5.588451856495198, 5.402575586045492, -3.7134955791907758, -5.564779255435256, -21.425048101456134, 3.9368114310061952, -2.5847617441676176, -8.895817259183348, 18.73157603718512, -1.2856894011546043, -1.7575286959672918, -4.369456458300412, -4.686343815512717, -10.231860522278376, -9.318147364461527, -7.907408134283828, -20.943069582551267, -6.981924638999963, 9.105932214444817, -7.388193315509694, -3.2633832102221962, -5.212460481344144, 3.943403734776013]
with mean = -3.912935670132901
Q Zusammensetzung:
Q = 0.0009897653462408035 * Summe([74448.7723846622 - 986.9390199508459 + 513.6000000000134] * 291600)
MST Day 1 p = 6.079595e-09  with t = 7.38e+02  (mean = 7.49 +- 5.659  vs. 2.48 +- 1.692
Subject z-score for real Q 
[6.897262023203587, -2.597092993275239, -1.2196286384778772, 1.0632321430763971, -13.037411539344458, -28.457370208354252, 22.293878587020977, 2.6000163554659426, -14.270034175624405, -25.648945215308164, -6.0530862908189755, -6.894294598525251, -4.234757888525205, 54.60527294772867, -0.2873274011188114, -10.148846039572948, -16.689706451839804, 6.198035285316327, -19.747400372569675, -15.057147552919064, 10.555097241536153, 3.8313469344245963, -6.245316243218369, -13.004703165180029, -12.096138094707209, -5.631689856344541]
with mean = -3.5875675079981395
Q Zusammensetzung:
Q = 0.0006856838481383013 * Summe([153366.90454151586 - 1263.1394007865083 + 729.5999999999807] * 585225)
MST Day 2 p = 1.132857e-09  with t = 9.76e+02  (mean = 11.9 +- 11.58  vs. 2.48 +- 1.694
___________SRTT_______
Subject z-score for real Q 
[-1.8019031574245652, -6.187758480919579, -13.498596181748193, 0.6911896316222553, -3.3176336354176637, -3.848074770826957, 0.10515682771943725, 1.3088394436193014, -14.13625423312862, -7.11416139139516, 2.6005673065505293, -10.757020526720366, -5.49121540200015, -4.4173766197293425, -3.4489561180042814, -1.6736801889493134, -2.840730097283762, 1.1655145518219654, -12.115812093534053, 0.5422786951719514, -1.3696884207538322]
with mean = -4.076443564825257
Q Zusammensetzung:
Q = 0.0017847795094391359 * Summe([10667.625783741787 - 545.2712163623693 + 270.0000000000045] * 67600)
SRTT Day 1 p = 0.01737108  with t = 1.59e+03  (mean = 4.69 +- 4.394  vs. 2.41 +- 1.787
Subject z-score for real Q 
[-8.80988279968929, 1.3228395820103196, -0.9510406180297424, -0.9470741472779323, 0.9177103675908729, 4.036514075340346, -0.01280169407732259, 4.485824132779869, -6.536468427330409, -1.9846064132648262, -1.2456888957088388, -1.5496676618363183, 2.2886747758624417, 0.672550579516163, -10.706040668529361, -8.520667301040517, -7.307746367153865, -0.8025278193023894, -3.3280485714920163, -2.2524464844005543, -5.904871276850771, -8.165060407079956]
with mean = -2.5136602745438226
Q Zusammensetzung:
Q = 0.0012994924025936812 * Summe([20143.124641704624 - 756.8830554845093 + 378.0000000000086] * 129600)
SRTT Day 2 p = 0.06163271  with t = 1.94e+03  (mean = 3.76 +- 3.255  vs. 2.4 +- 1.803
___________SEQ_______
Subject z-score for real Q 
[-26.842877626338613, 8.878265093056626, 14.91831251339346, 17.471025727360875, -5.417980707542625, 16.11327790981206, 33.380187366903215, 4.36686863525934, -4.519513298424678, -14.61037253144486, 7.720545521511623, 39.622636146419865, 9.55278910406907, 22.10087091196093, -6.05270753740784, -2.3797205717815615, 9.397288510445154, -15.20071836089727, -15.727999469278538, -1.52005365392278, 15.88441002865968, -22.477872002261204, 3.2038639166211382, 5.5518809040815595, -20.047722738051718, -9.648221137867662, -12.288737167980996]
with mean = 1.904730573568676
Q Zusammensetzung:
Q = 0.0008659729083980123 * Summe([59967.7902353175 - 1073.455993477208 + 621.5999999999971] * 360000)
SEQ Day 1 p = 6.129919e-14  with t = 4.9e+02  (mean = 13.5 +- 9.44  vs. 2.47 +- 1.703
Subject z-score for real Q 
[-67.44008375542415, 6.468701993373808, 12.405574140784449, 30.32830645803556, -0.6270550705929785, 3.2195328616791055, 9.66562074712441, 3.4173171253718553, -17.200038130568778, 2.5630253390667534, 14.886598148890002, 3.4050113506653577, 6.482959074508448, 1.009352041765217, 4.920099651630347, -15.050665016149564, -17.141544393809138, 6.593141459819358, 4.071273156069323, -15.31658031795082, -0.5506948002976657, 7.365029954990278, -5.200172859667287, 4.096730478086267, -19.27982963650475]
with mean = -1.4763355999641838
Q Zusammensetzung:
Q = 0.0007874740336954379 * Summe([72248.81762810561 - 1191.1017671627405 + 680.3999999999882] * 430336)
SEQ Day 2 p = 4.266286e-08  with t = 1.09e+03  (mean = 11.1 +- 13.78  vs. 2.47 +- 1.709
end estimation group q
performing an ANOVA
